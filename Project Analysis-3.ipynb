{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305bd37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob \n",
    "import numpy as np\n",
    "from scipy.interpolate import PchipInterpolator as pcip\n",
    "#from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import statistics as stat\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage.filters as ndif\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed75f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initilsetup____________________________________________________________________________________________________________\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\dell\\\\Desktop\\\\Test')\n",
    "path = os.getcwd()\n",
    "buildingfloor_files = glob.glob(os.path.join(path, \"*Floor5.csv\"))\n",
    "folder_name=path.rpartition('\\\\')[2] \n",
    "\n",
    "#relevant time details\n",
    "year=525600\n",
    "day=1440\n",
    "week=int(day*7)\n",
    "\n",
    "#Sections where both sensor power load details availabe (2019 floor5 zone1)\n",
    "datastart=int(96480+2*1440)  #96480 -67 days into 2019 start of T_room data in zone 1 2019 floor5 \n",
    "dataend=int(317520-720)      #317520 end of T_room data for zone 1\n",
    "\n",
    "\n",
    "#Importing building and ambient raw data\n",
    "timeyear=np.arange(0,525600,1)#Time in minutes for a year \n",
    "D_f = pd.read_csv(buildingfloor_files[0])\n",
    "D_f['Date'] =  pd.to_datetime(D_f['Date'], infer_datetime_format=True)\n",
    "Power=D_f.iloc[:,1]+D_f.iloc[:,2]+D_f.iloc[:,3]+D_f.iloc[:,4]\n",
    "\n",
    "ambienttemperature_file = glob.glob(os.path.join(path, \"Ambient values.csv\"))\n",
    "A_f = pd.read_csv(ambienttemperature_file[0])\n",
    "A_f.iloc[:,0]=A_f.iloc[:,0]+720\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6a9b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions used___________________________________________________________________________________________________________________________\n",
    "\n",
    "#Do not use. Only useful to fit data from daily data to give by-minute data \n",
    "def fancypantsinterpolator(D_f,one,two): #D_f:data frame containing the raw daily data,column of first entry becomes 'one' and next column becomes 'two'\n",
    "    j=0\n",
    "    A=np.zeros(525600)\n",
    "    for i in range(1440,525600,1):\n",
    "        if i%720==0 and (i/720)%2!=0:\n",
    "                y=[D_f.iloc[j,one],D_f.iloc[j+1,two]]\n",
    "                x=[i,i+720]\n",
    "                f=pcip(x, y, axis=0, extrapolate=None)\n",
    "                A[i]=D_f.iloc[j,one]\n",
    "        elif i%720==0 and (i/720)%2==0:\n",
    "                y=[D_f.iloc[j+1,two],D_f.iloc[j+1,one]]\n",
    "                x=[i,i+720]\n",
    "                f=pcip(x, y, axis=0, extrapolate=None)\n",
    "                A[i]=D_f.iloc[j+1,two]\n",
    "                j=j+1\n",
    "        elif i%720!=0:\n",
    "            A[i]=f(i)    \n",
    "    return A\n",
    "\n",
    "def knn_mean(ts, n):\n",
    "    out = np.copy(ts)\n",
    "    for i, val in enumerate(ts):\n",
    "        if np.isnan(val):\n",
    "            n_by_2 = np.ceil(n/2)\n",
    "            lower = np.max([0, int(i-n_by_2)])\n",
    "            upper = np.min([len(ts)+1, int(i+n_by_2)])\n",
    "            ts_near = np.concatenate([ts[lower:i], ts[i:upper]])\n",
    "            out[i] = np.nanmean(ts_near)\n",
    "    return out\n",
    "\n",
    "def plotrawdata(xTs,yTs,xTa,yTa,xACP,yACP,x1=datastart+day,x2=datastart+3*day):\n",
    "            fig, ax1 = plt.subplots()\n",
    "            ax1.set_xlabel('time, minutes')\n",
    "            ax1.title.set_text('Air Conditioning Data')\n",
    "            ax1.set_ylabel(str('Relative Humidity, %'), color = 'black') \n",
    "            ax1.plot(xTs, yTs, color = 'black', label='Zone RH')\n",
    "            ax1.plot(xTa, yTa,'--',color = 'black', linewidth=2,label='Ambient RH')\n",
    "            ax1.set_xlim([x1, x2])\n",
    "            ax1.set_ylim([10, 100])\n",
    "            ax1.legend(loc='lower center')\n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.set_xlim([x1, x2])\n",
    "            ax2.set_ylim([0, 60])\n",
    "            ax2.set_ylabel('AC load, kW', color = 'blue') \n",
    "            ax2.tick_params(axis ='y', labelcolor = 'blue')\n",
    "            ax2.plot(xACP, yACP, color = 'blue', label='')\n",
    "            return plt.show()\n",
    "\n",
    "def plotdistributiondata(x,yTs,yTamb,yaxis,title,sensor,ambient,x1=0,x2=100):\n",
    "            fig, ax1 = plt.subplots()\n",
    "            ax1.set_xlabel(str(yaxis))\n",
    "            ax1.title.set_text(str(title))\n",
    "            ax1.set_ylabel('Number Frequency', color = 'black') \n",
    "            ax1.plot(x, yTs, color = 'black', label=str(sensor))\n",
    "            ax1.plot(x, yTamb,'--',color = 'black', linewidth=2,label=str(ambient))\n",
    "            ax1.legend(loc='best')\n",
    "            ax1.set_xlim([x1, x2])\n",
    "            return plt.show()\n",
    "\n",
    "\n",
    "def running_mean_uniform_filter1d(x, N):\n",
    "    return ndif.uniform_filter1d(x, N, mode='constant', origin=-(N//2))[:-(N-1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a681d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Body2_____________________________________________________________________________________________________________________________________\n",
    "\n",
    "#Raw data plotting\n",
    "#Temperature raw data\n",
    "plotrawdata(timeyear,D_f.iloc[:,7],A_f.iloc[:,0],A_f.iloc[:,1],timeyear,Power)\n",
    "#RH raw data\n",
    "plotrawdata(timeyear,D_f.iloc[:,8],A_f.iloc[:,0],A_f.iloc[:,2],timeyear,Power)\n",
    "\n",
    "\n",
    "#Pruning data\n",
    "Dsubzone1=D_f.iloc[datastart:dataend,0:10]\n",
    "Dsubzone1['AC_load'] = Dsubzone1.iloc[:,1]+Dsubzone1.iloc[:,2]+Dsubzone1.iloc[:,3]+Dsubzone1.iloc[:,4]\n",
    "Dsubzone1=Dsubzone1.ffill()\n",
    "del Dsubzone1[\"z1_AC1(kW)\"]\n",
    "del Dsubzone1[\"z1_AC2(kW)\"]\n",
    "del Dsubzone1[\"z1_AC3(kW)\"]\n",
    "del Dsubzone1[\"z1_AC4(kW)\"]\n",
    "del Dsubzone1[\"z1_Light(kW)\"]\n",
    "del Dsubzone1[\"z1_Plug(kW)\"]\n",
    "del Dsubzone1[\"z1_S1(lux)\"]\n",
    "\n",
    "Asubzone1=A_f.iloc[datastart:dataend,1:3]\n",
    "#Nearest neighbors both sides 10 units used to get averaged point to fill in NANs\n",
    "#Dsubzone1.iloc[:,-1] = knn_mean(Dsubzone1.iloc[:,-1].values, 10)\n",
    "\n",
    "\n",
    "\n",
    "# Kernel density distributions of datasets\n",
    "kernelACloads = stats.gaussian_kde(Dsubzone1.iloc[:,-1])\n",
    "kernelTsens = stats.gaussian_kde(Dsubzone1.iloc[:,1])\n",
    "kernelRHsens = stats.gaussian_kde(Dsubzone1.iloc[:,2])\n",
    "kernelTamb = stats.gaussian_kde(Asubzone1.iloc[:,0])\n",
    "kernelRHamb = stats.gaussian_kde(Asubzone1.iloc[:,1])\n",
    "\n",
    "\n",
    "fun_x=np.arange(0,150,0.5)\n",
    "yac=kernelACloads(fun_x)\n",
    "yTsen=kernelTsens(fun_x)\n",
    "yRHsens=kernelRHsens(fun_x)\n",
    "yTamb=kernelTamb(fun_x)\n",
    "yRHamb=kernelRHamb(fun_x)\n",
    "\n",
    "#Temperature detail\n",
    "plotdistributiondata(fun_x,yTsen,yTamb,str(\"Temperature, degree Celsius\"),str(\"Temperature Settings\"),str(\"Zone Temperature\"),str(\"Ambient Temperature\"),10,40)\n",
    "#Relative Humidity detail\n",
    "plotdistributiondata(fun_x,yRHsens,yRHamb,str(\"Relative Humidity, %\"),str(\"Relative Humidity Settings\"),str(\"Zone RH\"),str(\"Ambient RH\"),25,100)\n",
    "\n",
    "\n",
    "#Assimilating building attributes and external attributes for training dataset\n",
    "Dmain=pd.DataFrame()\n",
    "pd.DataFrame(columns = ['Date','AC_Load_kW','T_sensor','RH_sensor','T_amb','RH_amb'])                      \n",
    "Dmain['Date']=Dsubzone1.iloc[:,0]\n",
    "Dmain['AC_Load_kW']=Dsubzone1.iloc[:,3]\n",
    "Dmain['T_sensor']=Dsubzone1.iloc[:,1]\n",
    "Dmain['RH_sensor']=Dsubzone1.iloc[:,2]\n",
    "Dmain['T_amb']=Asubzone1.iloc[:,0]\n",
    "Dmain['RH_amb']=Asubzone1.iloc[:,1]\n",
    "Dmain.index = pd.to_datetime(Dmain['Date'])\n",
    "del Dmain['Date']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61383afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis of all Data series: Seasonality and Trends_________________________________________________\n",
    "seasonality_dict = {}\n",
    "decompfreq = week #Try chnaging to day but I doubt if you'll get anything meaningful\n",
    "N=25000   #Smoothing window for rolling average (~1.7 days)\n",
    "for ts in Dmain.columns:\n",
    "    decompositions = sm.tsa.seasonal_decompose(Dmain[ts].dropna(), period=decompfreq)\n",
    "    # Store the results back\n",
    "    seasonality_dict[ts] = decompositions.seasonal\n",
    "# Plot seasonality\n",
    "rcParams[\"figure.figsize\"] = 16, 14\n",
    "pd.DataFrame(seasonality_dict)['2019-04-01 00:00:00':'2019-05-01 00:00:00'].plot(subplots=True, layout=(4, 2), linewidth=3)\n",
    "\n",
    "\n",
    "trend_dict = {}\n",
    "trend_dictoriginal= {}\n",
    "for ts in Dmain.columns:\n",
    "    decompositions = sm.tsa.seasonal_decompose(Dmain[ts].dropna().dropna(),period=decompfreq)\n",
    "    # Store back the results\n",
    "    trend_dict[ts] = pd.Series(decompositions.trend).rolling(window=N).mean().iloc[N-1:]\n",
    "    trend_dictoriginal[ts]=decompositions.trend\n",
    "#Plot Trends\n",
    "pd.DataFrame(trend_dict).plot(subplots=True, layout=(4, 3), linewidth=3)\n",
    "pd.DataFrame(trend_dictoriginal).plot(subplots=True, layout=(4, 3), linewidth=3)\n",
    "\n",
    "#Normalizing data \n",
    "normalized = Dmain.div(Dmain.max()).mul(100)  # Multiply by 100 to get percentages\n",
    "normalized['2019-04-01 00:00:00':'2019-05-01 00:00:00'].plot(figsize=(16, 8), title=\"Parameters of interest\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Normalized intensity (%)\")\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0c130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating correaltion matrix \n",
    "cmap = sns.diverging_palette(250, 15, s=75, l=40, n=9, center=\"light\", as_cmap=True) # Create a custom palette\n",
    "matrix = Dmain.corr(method=\"pearson\") # Compute corr matrix\n",
    "mask = np.triu(np.ones_like(matrix, dtype=bool))\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "sns.heatmap(matrix, mask=mask, cmap=cmap, square=True, annot=True, fmt=\".2f\", ax=ax)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Correlation in seasonality\n",
    "seasonality_dict = {ts: sm.tsa.seasonal_decompose(Dmain[ts].dropna(),period=decompfreq).seasonal for ts in Dmain.columns}\n",
    "seasonality_corr = pd.DataFrame(seasonality_dict).corr() # Compute corr matrix\n",
    "sns.clustermap(seasonality_corr, annot=True, square=True)\n",
    "plt.show()\n",
    "\n",
    "#Correlation in trends\n",
    "trend_dict = {ts: pd.Series(sm.tsa.seasonal_decompose(Dmain[ts].dropna(),period=decompfreq).trend).rolling(window=N).mean().iloc[N-1:] for ts in Dmain.columns}\n",
    "trend_dict = pd.DataFrame(trend_dict).corr()\n",
    "sns.clustermap(trend_dict, annot=True, square=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Checking for lag:Cross-corelation of time series with highest correaltion\n",
    "#Raw data\n",
    "Sensor=np.array(Dmain.iloc[:,1].values)\n",
    "Ambient=np.array(Dmain.iloc[:,3].values)\n",
    "crosscorrelation=sm.tsa.stattools.ccf(Sensor, Ambient, adjusted=False)\n",
    "plt.plot(crosscorrelation)\n",
    "plt.xlim([0,year/3])\n",
    "plt.title('Cross Correlation between Ambient and Sensor Temperatures')\n",
    "plt.xlabel('Time, min')\n",
    "plt.ylabel('Correlation Factor')\n",
    "\n",
    "\"\"\"\n",
    "SensorTrend=pd.Series(sm.tsa.seasonal_decompose(Dmain.iloc[:,1].values,period=decompfreq).trend).rolling(window=N).mean().iloc[N-1:]\n",
    "SensorTrend=SensorTrend.to_numpy()\n",
    "AmbientTrend=pd.Series(sm.tsa.seasonal_decompose(Dmain.iloc[:,3].values,period=decompfreq).trend).rolling(window=N).mean().iloc[N-1:]\n",
    "AmbientTrend=AmbientTrend.to_numpy()\n",
    "crosscorrelation2=sm.tsa.stattools.ccf(SensorTrend, AmbientTrend, adjusted=False)\n",
    "plt.plot(crosscorrelation2)\n",
    "plt.xlim([0,year/3])\n",
    "plt.title('Cross Correlation between Ambient and Sensor Temperatures')\n",
    "plt.xlabel('Time, min')\n",
    "plt.ylabel('Correlation Factor')\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "#Granger Causality Tests\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "grangercausalitytests(Dmain[['T_sensor', 'T_amb']], maxlag=2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb8aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAR Modelling_____________________________________________________________________________\n",
    "from statsmodels.tsa.api import VAR\n",
    "model = VAR(Dmain)\n",
    "xx = model.select_order(maxlags=12)\n",
    "results_summary=xx.summary()\n",
    "#Order chosen is 4\n",
    "model_fitted = model.fit(4)\n",
    "model_fitted.summary()\n",
    "\n",
    "\"\"\"\n",
    "from statsmodels.stats.stattools import durbin_watson #checking residuals to see how good the model is\n",
    "out = durbin_watson(model_fitted.resid)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec59fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction data\n",
    "datastart2=470237\n",
    "dataend2=D_f.shape[0]\n",
    "Dsubzone2=D_f.iloc[datastart2:dataend2,0:10]\n",
    "Dsubzone2['AC_load'] = Dsubzone2.iloc[:,1]+Dsubzone2.iloc[:,2]+Dsubzone2.iloc[:,3]+Dsubzone2.iloc[:,4]\n",
    "Dsubzone2=Dsubzone2.ffill()\n",
    "del Dsubzone2[\"z1_AC1(kW)\"]\n",
    "del Dsubzone2[\"z1_AC2(kW)\"]\n",
    "del Dsubzone2[\"z1_AC3(kW)\"]\n",
    "del Dsubzone2[\"z1_AC4(kW)\"]\n",
    "del Dsubzone2[\"z1_Light(kW)\"]\n",
    "del Dsubzone2[\"z1_Plug(kW)\"]\n",
    "del Dsubzone2[\"z1_S1(lux)\"]\n",
    "Asubzone2=A_f.iloc[datastart2:dataend2,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96804c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assimilating building attributes and external attributes for forcast/prediction dataset\n",
    "Dmain2=pd.DataFrame()\n",
    "pd.DataFrame(columns = ['Date','AC_Load_kW','T_sensor','RH_sensor','T_amb','RH_amb'])                      \n",
    "Dmain2['Date']=Dsubzone2.iloc[:,0]\n",
    "Dmain2['AC_Load_kW']=Dsubzone2.iloc[:,3]\n",
    "Dmain2['T_sensor']=Dsubzone2.iloc[:,1]\n",
    "Dmain2['RH_sensor']=Dsubzone2.iloc[:,2]\n",
    "Dmain2['T_amb']=Asubzone2.iloc[:,0]\n",
    "Dmain2['RH_amb']=Asubzone2.iloc[:,1]\n",
    "Dmain2.index = pd.to_datetime(Dmain2['Date'])\n",
    "del Dmain2['Date']\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#getting the predicted data \n",
    "def invert_transformation(D_main, D_main2, second_diff=False):\n",
    "    ##Revert back the differencing to get the forecast to original scale.\n",
    "    df_fc = D_main2.copy()\n",
    "    columns = D_main.columns\n",
    "    for col in columns:        \n",
    "        # Roll back 2nd Diff\n",
    "        if second_diff:\n",
    "            df_fc[str(col)+'_1d'] = (D_main[col].iloc[-1]-D_main[col].iloc[-2]) + df_fc[str(col)+'_2d'].cumsum()\n",
    "        # Roll back 1st Diff\n",
    "        df_fc[str(col)+'_forecast'] = D_main[col].iloc[-1] + df_fc[str(col)+'_1d'].cumsum()\n",
    "    return df_fc\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "nobs=4\n",
    "fc = model_fitted.forecast(y=Dmain2, steps=nobs)\n",
    "df_forecast = pd.DataFrame(fc, index=Dmain.index[-nobs:], columns=Dmain.columns)\n",
    "      \n",
    "df_forecast.loc[:, ['rgnp_forecast', 'pgnp_forecast', 'ulc_forecast', 'gdfco_forecast',\n",
    "                   'gdf_forecast', 'gdfim_forecast', 'gdfcf_forecast', 'gdfce_forecast']]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#Plotting \n",
    "fig, axes = plt.subplots(nrows=int(len(Dmain1.columns)/2), ncols=2, dpi=150, figsize=(10,10))\n",
    "for i, (col,ax) in enumerate(zip(Dmain2.columns, axes.flatten())):\n",
    "    df_results[col+'_forecast'].plot(legend=True, ax=ax).autoscale(axis='x',tight=True)\n",
    "    Dmain2[col][-nobs:].plot(legend=True, ax=ax);\n",
    "    ax.set_title(col + \": Forecast vs Actuals\")\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    ax.spines[\"top\"].set_alpha(0)\n",
    "    ax.tick_params(labelsize=6)\n",
    "\n",
    "plt.tight_layout()\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "#Formula saving\n",
    "decompfreq = week\n",
    "decomposition = sm.tsa.seasonal_decompose(Dsubzone1.iloc[:,-1].values,period=decompfreq)\n",
    "trend = decomposition.trend\n",
    "season = decomposition.seasonal \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "#This section contains code that obtained daily data of temperature and relative humidity to interpolate and obtain minute by minute data\n",
    "#Since that data is already available as a csv file this section is commented out\n",
    "\n",
    "ambienttemperature_file = glob.glob(os.path.join(path, \"2019-Ambient-temperature-relativehumidity.csv\"))\n",
    "#Reading the daily ambient Temperataure and Relative humidity values (Max, Av and Min) for the year 2019\n",
    "AmbientTandR_df = pd.read_csv(ambienttemperature_file[0])\n",
    "#Converting temperature from fahrenheit to celsius \n",
    "AmbientTandR_df.iloc[:,1]=(AmbientTandR_df.iloc[:,1]-32)*(5/9)\n",
    "AmbientTandR_df.iloc[:,2]=(AmbientTandR_df.iloc[:,2]-32)*(5/9)\n",
    "AmbientTandR_df.iloc[:,3]=(AmbientTandR_df.iloc[:,3]-32)*(5/9)\n",
    "\n",
    "#obtaining interpolated data\n",
    "T_amb=fancypantsinterpolator(AmbientTandR_df,3,1)\n",
    "RH_amb=fancypantsinterpolator(AmbientTandR_df,4,6)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
